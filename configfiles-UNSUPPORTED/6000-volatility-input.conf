# Logstash Input Configuration for Volatility Memory Forensics
# ==============================================================
#
# SOF-ELK Architecture Note:
# --------------------------
# SOF-ELK uses Filebeat to monitor filesystem directories, NOT Logstash file inputs.
#
# Data flow:
#   1. Files placed in /logstash/volatility/<plugin>/*.json
#   2. Filebeat watches these directories (configured in filebeat.yml)
#   3. Filebeat sends to Logstash Beats input (port 5044)
#   4. Logstash filters process the events (configs 6001-6012)
#   5. Data indexed to Elasticsearch
#
# Required Directory Structure on SOF-ELK:
# -----------------------------------------
#   /logstash/volatility/pslist/   - Process list (windows.pslist)
#   /logstash/volatility/pstree/   - Process tree (windows.pstree)
#   /logstash/volatility/psscan/   - Process scan (windows.psscan)
#   /logstash/volatility/netscan/  - Network connections (windows.netscan)
#   /logstash/volatility/cmdline/  - Command lines (windows.cmdline)
#   /logstash/volatility/netstat/  - Network stats (windows.netstat)
#
# Setup Commands (on SOF-ELK VM):
# --------------------------------
#   sudo mkdir -p /logstash/volatility/{pslist,pstree,psscan,netscan,cmdline,netstat}
#   sudo chown -R filebeat:filebeat /logstash/volatility/
#   sudo chmod 755 /logstash/volatility/
#
# Filebeat Configuration:
# -----------------------
# Add the filebeat-volatility.yml configuration to SOF-ELK's filebeat.yml
# See: ../filebeat/filebeat-volatility.yml
#
# The Beats input is already configured in SOF-ELK (typically in a file like
# /etc/logstash/conf.d/0001-input-beats.conf or similar) and listens on port 5044.
#
# NO ADDITIONAL INPUT CONFIGURATION IS NEEDED HERE.
#
# Filebeat will automatically tag events with:
#   - type: "volatility-<plugin>"  (e.g., "volatility-netscan")
#   - tags: ["volatility", "<plugin>", "memory_forensics"]
#
# These fields are used by our filter configurations (6001-6012) to route
# events to the correct processing pipeline.
#
# ==============================================================
# IMPORTANT: File Size Requirement
# ==============================================================
# Filebeat 9+ uses fingerprinting and requires files to be at least 1,024 bytes.
# Smaller files will be ignored. Our NDJSON files from batch_process.py typically
# exceed this size, but be aware if creating custom inputs.
#
# ==============================================================
# Verification Steps:
# ==============================================================
# 1. Check Filebeat is running:
#      sudo systemctl status filebeat
#
# 2. Test Filebeat configuration:
#      sudo filebeat test config
#
# 3. Check Filebeat is harvesting files:
#      sudo tail -f /var/log/filebeat/filebeat.log
#
# 4. Verify Logstash is receiving events:
#      sudo tail -f /var/log/logstash/logstash-plain.log
#
# 5. Check Elasticsearch indices:
#      curl -s localhost:9200/_cat/indices/volatility-* | sort
#
# ==============================================================
# Data Ingestion Workflow:
# ==============================================================
# 1. Run batch_process.py with --output-dir /logstash/volatility
# 2. NDJSON files are created in /logstash/volatility/<plugin>/
# 3. Filebeat detects new files and parses NDJSON
# 4. Filebeat sends to Logstash on localhost:5044
# 5. Logstash applies filters based on event 'type' field
# 6. Enriched data sent to Elasticsearch
# 7. Query in Kibana using index pattern: volatility-*
#
