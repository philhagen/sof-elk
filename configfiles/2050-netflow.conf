# SOF-ELKÂ® Configuration File
# (C)2025 Lewes Technology Consulting, LLC
#
# This file contains filters, transforms, and enrichments for NetFlow records

filter {

  # These are just status updates periodically sent by some exporters (incl. UniFi Dream Machine).
  # Not immediately useful, so just dropping them unless needed in the future.
  if [labels][type] == "netflow" and [netflow][type] == "netflow_options" {
    drop { }
  }

  # tag with any known uniquely-identifying characteristics are present
  if [labels][type] == "archive-netflow" {
    # this field is present in JSON-formatted GCP VPC Flow logs
    if [raw][logName] {
      mutate {
        add_tag => [ "gcp-vpcflow" ]
        add_field => { "[cloud][provider]" => "gcp" }
      }

    # this field is present in a specific export format of AWS VPC Flow logs - see Issue #349
    } else if [raw][account_id] {
      mutate {
        add_tag => [ "aws-vpcflow-349" ]
        add_field => { "[cloud][provider]" => "aws" }
      }
    }

    if "gcp-vpcflow" not in [tags]  and "aws-vpcflow-349" not in [tags] {
      # drop the header row and NODATA rows from Amazon VPC Flow entries
      if [message] =~ "^version"  or [message] =~ "^account-id" or [message] =~ "NODATA" { drop { } }

      grok {
        patterns_dir => [ "/usr/local/sof-elk/grok-patterns" ]
        match => { "message" => [
          # nfdump2sof-elk.sh
          "(?:%{IPORHOST:[netflow][exporter][ip]})?(?:%{SPACE})?%{NONNEGINT:[destination][as][number]:int}%{SPACE}%{NONNEGINT:[destination][netmask]:int}%{SPACE}%{NONNEGINT:[netflow][engine_type]:int}/%{NONNEGINT:[netflow][engine_id]:int}%{SPACE}%{TIMESTAMP_NETFLOW:flow_start_raw}%{SPACE}%{NONNEGINT:[netflow][delta_flow_count]}%{SPACE}%{NONNEGINT}%{SPACE}%{NONNEGINT:[source][bytes]}%{SPACE}%{NONNEGINT:[source][packets]}%{SPACE}%{NONNEGINT:[observer][ingress][interface][id]:int}%{SPACE}%{IP:[destination][ip]}%{SPACE}%{IP:[next_hop][ip]}%{SPACE}%{IP:[source][ip]}%{SPACE}(%{ICMP_TYPECODE}|%{NONNEGINT:[destination][port]:int})%{SPACE}%{NONNEGINT:[source][port]:int}%{SPACE}%{TIMESTAMP_NETFLOW:[flow_end_raw]}%{SPACE}%{NONNEGINT:[observer][egress][interface][id]:int}%{SPACE}%{INT:[network][iana_number]:int}%{SPACE}%{NONNEGINT}%{SPACE}%{NONNEGINT}%{SPACE}%{NONNEGINT:[source][as][number]:int}%{SPACE}%{NONNEGINT:[source][netmask]:int}%{SPACE}%{NONNEGINT:[source][tos]:int}%{SPACE}%{NOTSPACE:[netflow][tcp_flags_str]}%{SPACE}%{NONNEGINT:[netflow][exporter][version]:int}",

          # aws-vpcflow2sof-elk.sh
          "%{INT:[aws][vpcflow][version]} %{NOTSPACE:[aws][vpcflow][account_id]} %{NOTSPACE:[aws][vpcflow][interface_id]} %{IP:[source][ip]} %{IP:[destination][ip]} %{INT:[source][port]} %{INT:[destination][port]} %{INT:[network][iana_number]:int} %{INT:[source][packets]} %{INT:[source][bytes]} %{INT:flow_start_raw} %{INT:flow_end_raw} %{WORD:[aws][vpcflow][action]} %{WORD:[aws][vpcflow][log_status]}",
          # AWS VPC Flow v5
          "%{INT:[aws][vpcflow][account_id]} %{WORD:[aws][vpcflow][action]} %{NOTSPACE:[cloud][availability_zone]} %{INT:[source][bytes]} %{IP:[destination][ip]} %{INT:[destination][port]} %{INT:flow_end_raw} %{WORD:[network][direction]} %{NOTSPACE:[aws][vpcflow][instance_id]} %{NOTSPACE:[aws][vpcflow][interface_id]} %{WORD:[aws][vpcflow][log_status]} %{INT:[source][packets]} %{NOTSPACE:[aws][vpcflow][destination_service]} %{IP:[original_destination][ip]} %{NOTSPACE:[aws][vpcflow][source][service]} %{IP:[original_source][ip]} %{INT:[network][iana_number]:int} %{NOTSPACE:[cloud][region]} %{IP:[source][ip]} %{INT:[source][port]} %{INT:flow_start_raw} %{NOTSPACE:[aws][vpcflow][vpc_id]} %{INT:[aws][vpcflow][version]} %{WORD:[aws][vpcflow][type]} %{NOTSPACE:[aws][vpcflow][traffic_path]} %{INT:[netflow][tcp_control_bits]} %{NOTSPACE:[aws][vpcflow][subnet_id]} %{NOTSPACE:[aws][vpcflow][sublocation][type]} %{NOTSPACE:[aws][vpcflow][sublocation][id]}",

          # azure-vpcflow2sof-elk.sh
          "^%{GUID:[exporter][guid]},%{COMMONMAC:[exporter][mac]},%{POSINT:[aws][vpcflow][version]},%{DATA:[azure][flow_rule]},%{DATA:[azure][flow_source_file]},%{WORD:[azure][flow_state]},%{POSINT:flow_start_raw},%{POSINT:flow_end_raw},%{IP:[source][ip]},%{INT:[source][port]},%{IP:[destination][ip]},%{INT:[destination][port]},%{INT:[network][iana_number]:int},%{INT:[source][bytes]},%{INT:[source][packets]},%{INT:[destination][bytes]},%{INT:[destination][packets]},%{WORD:[network][direction]},%{WORD:[event][type]}"
          ]
        }
        remove_field => [ "message", "MSECOND" ]
      }

      # this occurs sometimes with AWS VPC Flow records
      if [aws][vpcflow][account_id] and [aws][vpcflow][account_id] == "unknown" {
        mutate {
          remove_field => [ "[aws][vpcflow][account_id]" ]
        }
      }

    # Google Compute Platform VPC Flow Logs in JSON format
    # reference: https://cloud.google.com/vpc/docs/flow-logs#VpcDetails
    } else if "gcp-vpcflow" in [tags] {
      mutate {
        # todo: these seem superfluous or duplicative of [gcp][*][vpc][vpc_name]
        #        "[raw][jsonPayload][src_instance][vm_name]" => "[cloud][origin][instance][name]"
        #        "[raw][jsonPayload][dest_instance][vm_name]" => "[cloud][target][instance][name]"
        rename => {
          "[raw][jsonPayload][start_time]" => "flow_start_raw"
          "[raw][jsonPayload][end_time]" => "flow_end_raw"
          "[raw][jsonPayload][connection][src_ip]" => "[source][ip]"
          "[raw][jsonPayload][connection][dest_ip]" => "[destination][ip]"
          "[raw][jsonPayload][connection][src_port]" => "[source][port]"
          "[raw][jsonPayload][connection][dest_port]" => "[destination][port]"
          "[raw][jsonPayload][connection][protocol]" => "[network][iana_number]"
          "[raw][jsonPayload][bytes_sent]" => "[source][bytes]"
          "[raw][jsonPayload][packets_sent]" => "[source][packets]"
          "[raw][jsonPayload][src_instance][project_id]" => "[gcp][source][instance][project_id]"
          "[raw][jsonPayload][src_instance][region]" => "[gcp][source][instance][region]"
          "[raw][jsonPayload][src_instance][zone]" => "[gcp][source][instance][zone]"
          "[raw][jsonPayload][dest_instance][project_id]" => "[gcp][destination][instance][project_id]"
          "[raw][jsonPayload][dest_instance][region]" => "[gcp][destination][instance][region]"
          "[raw][jsonPayload][dest_instance][zone]" => "[gcp][destination][instance][zone]"
          "[raw][jsonPayload][src_vpc][project_id]" => "[gcp][source][vpc][project_id]"
          "[raw][jsonPayload][src_vpc][subnetwork_name]" => "[gcp][source][vpc][subnetwork_name]"
          "[raw][jsonPayload][src_vpc][vpc_name]" => "[gcp][source][vpc][vpc_name]"
          "[raw][jsonPayload][dest_vpc][project_id]" => "[gcp][destination][vpc][project_id]"
          "[raw][jsonPayload][dest_vpc][subnetwork_name]" => "[gcp][destination][vpc][subnetwork_name]"
          "[raw][jsonPayload][dest_vpc][vpc_name]" => "[gcp][destination][vpc][vpc_name]"
          "[raw][jsonPayload][src_location][asn]" => "[source][as][number]"
          "[raw][jsonPayload][dest_location][asn]" => "[destination][as][number]"
          "[raw][jsonPayload][reporter]" => "[gcp][vpcflow][reporter]"
          "[raw][logName]" => "[gcp][log_name]"
          "[raw][resource][labels][location]" => "[cloud][resource][location]"
          "[raw][resource][project_id]" => "[cloud][project][id]"
          "[raw][resource][subnetwork_id]" => "[network][subnetwork][id]"
          "[raw][resource][subnetwork_name]" => "[network][subnetwork][name]"
          "[raw][resource][type]" => "[cloud][resource][type]"
        }
      }
      if [gcp][vpcflow][reporter] == "SRC" {
        mutate {
          copy => { "[source][ip]" => "[netflow][exporter][ip]" }
        }
      } else if [gcp][vpcflow][reporter] == "DEST" {
        mutate {
          copy => { "[destination][ip]" => "[netflow][exporter][ip]" }
        }
      }

      # remove remaining fields
      mutate {
        remove_field => [ "raw" ]
      }

    # This is a specific form of AWS VPC Flow Logs discussed in Issue #349
    } else if "aws-vpcflow-349" in [tags] {
      mutate {
        rename => {
          "[raw][start_time]" => "flow_start_raw"
          "[raw][end_time]" => "flow_end_raw"
          "[raw][in_bytes]" => "[source][bytes]"
          "[raw][out_bytes]" => "[destination][bytes]"
          "[raw][interface_local_ip]" => "[source][ip]"
          "[raw][remote_ip]" => "[destination][ip]"
          "[raw][local_port]" => "[source][port]"
          "[raw][remote_port]" => "[destination][port]"
          "[raw][vpc_id]" => "[aws][vpcflow][vpc_id]"
          "[raw][instance_id]" => "[aws][vpcflow][instance_id]"
          "[raw][subnet_id]" => "[aws][vpcflow][subnet_id]"
          "[raw][account_id]" => "[aws][vpcflow][account_id]"
          "[raw][interface_id]" => "[aws][vpcflow][interface_id]"
          "[raw][protocol]" => "[network][iana_number]"
          "[raw][filename]" => "[aws][vpcflow][file][name]"
          "[raw][source_az]" => "[cloud][availability_zone]"
        }
      }

      # This is not perfect due to how logstash conflates "field existence" and "boolean value in a field".
      # We're assuming this field will exist in the first place - if it is absent, the field value will be
      #  set to "REJECT".  This is not ideal, but an acceptable risk unless we discover records without
      #  the rejected_packet field present.
      if [raw][rejected_packet] {
        mutate {
          add_field => { "[aws][vpcflow][action]" => "ACCEPT" }
        }
      } else {
        mutate {
          add_field => { "[aws][vpcflow][action]" => "REJECT" }
        }
      }

      # this format does not include packet counts, but they can be approximated from the average packet size and total byte count
      if [raw][avg_in_packet_size] != 0 {
        ruby {
          code => "event.set('source.packets', (event.get('[source][bytes]') / event.get('[raw][avg_in_packet_size]')))"
          add_tag => [ "calculated_source_packets"]
        }
      }
      if [raw][avg_out_packet_size] != 0 {
        ruby {
          code => "event.set('destination.packets', (event.get('[destination][bytes]') / event.get('[raw][avg_out_packet_size]')))"
          add_tag => [ "calculated_destination_packets" ]
        }
      }

      # remove remaining fields
      mutate {
        remove_field => [ "raw" ]
      }
    }
  }

  if [labels][type] == "netflow" {
    # use the most granular timestamps available
    if [netflow][flow_start_nanoseconds] and [netflow][flow_end_nanoseconds] {
      mutate {
        copy => {
          "[netflow][flow_start_nanoseconds]" => "flow_start_raw"
          "[netflow][flow_end_nanoseconds]" => "flow_end_raw"
        }
      }
    } else if [netflow][flow_start_microseconds] and [netflow][flow_end_microseconds] {
      mutate {
        copy => {
          "[netflow][flow_start_microseconds]" => "flow_start_raw"
          "[netflow][flow_end_microseconds]" => "flow_end_raw"
        }
      }
    } else if [netflow][flow_start_milliseconds] and [netflow][flow_end_milliseconds] {
      mutate {
        copy => {
          "[netflow][flow_start_milliseconds]" => "flow_start_raw"
          "[netflow][flow_end_milliseconds]" => "flow_end_raw"
        }
      }
    } else if [netflow][flow_start_seconds] and [netflow][flow_end_seconds] {
      mutate {
        copy => {
          "[netflow][flow_start_seconds]" => "flow_start_raw"
          "[netflow][flow_end_seconds]" => "flow_end_raw"
        }
      }
    }

    # use the most granular duration available, but convert to floating point seconds
    if [netflow][flow_duration_microseconds] {
      ruby {
        code => "event.set('netflow.flow_duration', event.get('[netflow][flow_duration_microseconds]').to_i / 1000000)"
      }
    } else if [netflow][flow_duration_milliseconds] {
      ruby {
        code => "event.set('netflow.flow_duration', event.get('[netflow][flow_duration_milliseconds]').to_i / 1000)"
      }
    } else if [netflow][connection_sum_duration_seconds] {
      mutate {
        copy => { "[netflow][connection_sum_duration_seconds]" => "[netflow][flow_duration]" }
      }
    }

    if [netflow][exporter][address] and ![netflow][exporter][ip] {
      grok {
        match => [ "[netflow][exporter][address]", "^%{IP:[netflow][exporter][ip]}" ]
      }
    }

    # this is strictly cosmetic
    mutate {
      remove_tag => [ "process_archive" ]
    }
  }

  if [labels][type] in [ "netflow", "archive-netflow" ] {
    ## unify timestamp formats between live and archive
    ##  2014-05-11 16:25:11.841 (archived from nfdump)
    date {
      match => [ "flow_start_raw", "YYYY-MM-dd'THH:mm:ss.SSS'Z", "YYYY-MM-dd HH:mm:ss.SSS", "ISO8601", "UNIX_MS", "UNIX" ]
      target => "@timestamp"
    }
    date {
      match => [ "flow_start_raw", "YYYY-MM-dd'THH:mm:ss.SSS'Z", "YYYY-MM-dd HH:mm:ss.SSS", "ISO8601", "UNIX_MS", "UNIX" ]
      target => "[netflow][flow_start]"
    }
    date {
      match => [ "flow_end_raw", "YYYY-MM-dd'THH:mm:ss.SSS'Z", "YYYY-MM-dd HH:mm:ss.SSS", "ISO8601", "UNIX_MS", "UNIX" ]
      target => "[netflow][flow_end]"
    }

    if ![netflow][flow_duration] {
      # Calculate the duration from flow_start and flow_end
      ruby {
        init => "require 'date'"
        code => "event.set('netflow.flow_duration', (event.get('[netflow][flow_end]') - event.get('[netflow][flow_start]')))"
        add_tag => [ "calculated_duration" ]
      }
    }

    # if not TCP, no need for the tcp_flags fields
    if [network][iana_number] != 6 {
      mutate {
        remove_field => [ "[netflow][tcp_flags_str]", "[netflow][tcp_control_bits]" ]
      }

    } else if [netflow][tcp_flags_str] {
      # convert TCP flag value (integer or text string) to an array and hex byte string
      ruby {
        path => "/usr/local/sof-elk/supporting-scripts/tcp_flags_to_array.rb"
        script_params => {
          "source_field" => "[netflow][tcp_flags_str]"
          "source_type" => "str"
        }
        remove_field => [ "[netflow][tcp_flags_str]" ]
      }
    } else if [netflow][tcp_control_bits] {
      ruby {
        path => "/usr/local/sof-elk/supporting-scripts/tcp_flags_to_array.rb"
        script_params => {
          "source_field" => "[netflow][tcp_control_bits]"
          "source_type" => "int"
        }
      }
    }

    # replace the numerical protocol number with a text equivalent
    if [network][iana_number] and ![network][transport] {
      translate {
        dictionary_path => "/usr/local/sof-elk/lib/dictionaries/ip_proto_int2name.yaml"
        source => "[network][iana_number]"
        target => "[network][transport]"
      }
    }

    # populate additional fields or modify as needed to match flow sources
    if ![netflow][exporter][ip] {
      mutate {
        add_field => { "[netflow][exporter][ip]" => "0.0.0.0" }
      }
    }
    if ![netflow][delta_flow_count] or [netflow][delta_flow_count] == "0" {
      mutate {
        add_field => { "[netflow][delta_flow_count]" => "1" }
      }
    }
    if ![network][missed_bytes] {
      mutate {
        add_field => { "[network][missed_bytes]" => "0" }
      }
    }
    if ![destination][bytes] {
      mutate {
        add_field => { "[destination][bytes]" => "0" }
      }
    }
    # I have no idea why the ![field] logic fails for ruby-inserted fields such as with the aws-vpcflow-349 format.
    # The "and not tagged" logic is admittedly a workaround I'd rather not use
    if ![destination][packets] and "calculated_destination_packets" not in [tags] {
      mutate {
        add_field => { "[destination][packets]" => "0" }
      }
    }
    if ![source][bytes] {
      mutate {
        add_field => { "[source][bytes]" => "0" }
      }
    }
    # I have no idea why the ![field] logic fails for ruby-inserted fields such as with the aws-vpcflow-349 format.
    # The "and not tagged" logic is admittedly a workaround I'd rather not use
    if ![source][packets] and "calculated_source_packets" not in [tags] {
      mutate {
        add_field => { "[source][packets]" => "0" }
      }
    }

    # convert types
    mutate {
      convert => {
        "[destination][bytes]" => "integer"
        "[source][bytes]" => "integer"
        "[netflow][delta_flow_count]" => "integer"
        "[destination][packets]" => "integer"
        "[source][packets]" => "integer"
        "[network][missed_bytes]" => "integer"
        "[aws][vpcflow][account_id]" => "integer"
      }
      add_field => { "[sof-elk][path]" => "NetFlow from %{[netflow][exporter][ip]}" }
      remove_field => [ "flow_start_raw", "flow_end_raw" ]
    }
  }

  if [labels][type] == "archive-netflow" {
    if [network][iana_number] == "1" {
      mutate {
        replace => {
          "[source][port]" => "%{icmp_type}"
          "[destination][port]" => "%{icmp_code}"
        }
      }
      mutate {
        remove_field => [ "icmp_type", "icmp_code" ]
      }
    }
  }
}
